The sessions collected with crowdsourcing need some parsing/fixing before being analyzed.
- This includes recomputing some ROUGE scores, which for some reason is wrong when computed udring session collection. (step 6)
    - Since this fix takes time, steps 1-5 explain how to recompute scores only for the newly added sessions.
- Also the sessions are converted to somewhat of a different format to be consistent with the simulations format and for easier (manual) reading. (step 7)
Finally, the parsed sessions are analyzed in steps 8, 9 and 10.

1. From the server, copy the new sessions and the added sentences in the db file to RealSessions/results_table.json
2. Run MechanicalTurk\results\cleanDBJson.py with DB_FILE = '../RealSessions/results_table.json'
3. Change the name of RealSessions/results_table_clean.json to RealSessions/results_table_clean_bad.json
4. Change the name of RealSessions/results_table_clean_fixed.json to RealSessions/results_table_clean_fixed_.json
5. Copy the new session(s) from RealSessions/results_table_clean_bad.json to RealSessions/results_table_clean_fixed_.json
6. Run FixRougeScoresInResultsFile.ipynb with
	resultsFilePath = '../MechanicalTurk/RealSessions/results_table_clean_fixed_.json'
	resultsFixedFilePath = '../MechanicalTurk/RealSessions/results_table_clean_fixed.json'
	ONLY_TOPICS = [<newly added sessions topic ids>]
	ONLY_WORKERS = [<newly added sessions worker ids>]
7. Run MechanicalTurk/results/generateResultsJson.py with
	DB_FILE = '../RealSessions/results_table_clean_fixed.json'
	OUTPUT_JSON_FOLDER = '../RealSessions'
	NUM_MISTAKES_ALLOWED_IN_QUESTIONNAIRE = 4
	SESSION_INTERSECTION_MIN_COUNT = -1
8. Run CompareSessionResults.ipynb with
	inputFiles = [
	    '../MechanicalTurk/RealSessions/results_SummarizerClustering_avg.json',
	    '../MechanicalTurk/RealSessions/results_SummarizerTextRankPlusLexical_avg.json', ...]
9. Run Corellations.ipynb for correlations between different metrics
10. Run ShowSessionsStats.ipynb for statistics on the sessions file